{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load data from csv\n",
    "TRAINING_DATA_PATH = 'C:/Users/canla/Desktop/Grad_School/AAI_695_Applied_ML/Project/AI-genre-prediction/data_processed/Iteration_2/training_data_Final.csv'\n",
    "TEST_DATA_PATH = 'C:/Users/canla/Desktop/Grad_School/AAI_695_Applied_ML/Project/AI-genre-prediction/data_processed/Iteration_2/test_data_Final.csv'\n",
    "train_set = pd.read_csv(TRAINING_DATA_PATH)\n",
    "test_set = pd.read_csv(TEST_DATA_PATH)\n",
    "\n",
    "# Split train and test set into features and response variables\n",
    "y_train = train_set[\"Genre\"].to_numpy()\n",
    "X_train = train_set.iloc[:, 1:].to_numpy()\n",
    "y_test = test_set[\"Genre\"].to_numpy()\n",
    "X_test = test_set.iloc[:, 1:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier (Without Optimized Hyperparameters) -- Train Set: 0.2432095308403126\n",
      "Random Forest Classifier (Without Optimized Hyperparameters) -- Test Set: 0.2388758782201405\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# 1) Random Forest (Without Optimized hyperparameters -- Initial Guess)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, max_leaf_nodes=10, n_jobs=-1, criterion='gini', random_state=42)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy score (Without optimized hyperparameters -- Initial Guess)\n",
    "print(\"Random Forest Classifier (Without Optimized Hyperparameters) -- Train Set:\", rnd_clf.score(X_train, y_train))\n",
    "print(\"Random Forest Classifier (Without Optimized Hyperparameters) -- Test Set:\", rnd_clf.score(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "# Use RandomSearchCV to try and find optimum hyperparameters for random trees classifier\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 500, 1000],\n",
    "    'max_features': [10, 20, 30, 50],\n",
    "    'max_depth': [5, 10, 20, 30, None],\n",
    "    'min_samples_split': [50, 100, 500, 1000],\n",
    "    'min_samples_leaf': [50, 100, 200, 500],\n",
    "}\n",
    "tree_clf = RandomForestClassifier()\n",
    "\n",
    "# Using negative mean squared error score for classification\n",
    "grid_search = RandomizedSearchCV(tree_clf, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best combination of hyperparameters\n",
    "print(\"Best hyperparameters for Random Forest:\", grid_search.best_params_)\n",
    "\n",
    "# Use RandomSearchCV to try and find optimum hyperparameters for extra trees classifier\n",
    "extra_trees_clf = ExtraTreesClassifier()\n",
    "\n",
    "# Using negative mean squared error score for classification\n",
    "grid_search = RandomizedSearchCV(extra_trees_clf, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best combination of hyperparameters\n",
    "print(\"Best hyperparameters for Extra Trees:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier (Optimized Hyperparameters) -- Train Set: 0.3467403202403075\n",
      "Random Forest Classifier (Optimized Hyperparameters) -- Test Set: 0.3069952143366256\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# 2) New random forest classifier (with optimized hyperparameters -- using results from RandomSearchCV)\n",
    "rnd_clf_optimized = RandomForestClassifier(n_estimators=100, min_samples_split=100, min_samples_leaf=100, max_features=30, max_depth=None, criterion='gini', random_state=42)\n",
    "rnd_clf_optimized.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy score (With optimized hyperparameters)\n",
    "print(\"Random Forest Classifier (Optimized Hyperparameters) -- Train Set:\", rnd_clf_optimized.score(X_train, y_train))\n",
    "print(\"Random Forest Classifier (Optimized Hyperparameters) -- Test Set:\", rnd_clf_optimized.score(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "\n",
    "\n",
    "# 3) Now, let's try performing bagging on the random forest classifier (with the optimized hyperparameters)\n",
    "rnd_clf_bagging = BaggingClassifier(base_estimator=RandomForestClassifier(n_estimators=100, min_samples_split=100, min_samples_leaf=100, max_features=30, max_depth=None, criterion='gini', random_state=42), n_estimators=10, random_state=42)\n",
    "rnd_clf_bagging.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy score (With optimized hyperparameters and bagging)\n",
    "print(\"Random Forest Classifier (Optimized Hyperparameters and Bagging) -- Train Set:\", rnd_clf_bagging.score(X_train, y_train)) # 0.32894636356693735\n",
    "print(\"Random Forest Classifier (Optimized Hyperparameters and Bagging) -- Test Set:\", rnd_clf_bagging.score(X_test, y_test)) # 0.30017309846247836"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "\n",
    "# 4) Extra Trees Classifier using optimized parameters\n",
    "rnd_clf_extra_trees = ExtraTreesClassifier(n_estimators=50, min_samples_split=100, min_samples_leaf=500, max_features=50, max_depth=30, criterion='gini', random_state=42)\n",
    "rnd_clf_extra_trees.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy score (Extra trees classifier)\n",
    "print(\"Extra Trees Classifier (Optimized Hyperparameters) -- Train Set:\", rnd_clf_extra_trees.score(X_train, y_train)) # 0.2623017590306239\n",
    "print(\"Extra Trees Classifier (Optimized Hyperparameters) -- Test Set:\", rnd_clf_extra_trees.score(X_test, y_test)) # 0.2559820792180022624 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
